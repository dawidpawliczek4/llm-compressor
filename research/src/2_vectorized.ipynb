{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8001277eaf6afa",
   "metadata": {},
   "source": [
    "# 2. Vectorized Model\n",
    "\n",
    "Wersja wektoryzowana modelu baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7dc4e566ec8b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T17:46:20.831104Z",
     "start_time": "2026-01-23T17:46:20.330880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import constriction\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Konfiguracja\n",
    "TRAIN_PATH = \"../data/all_silesia.bin\"\n",
    "TEST_PATH = \"../data/all_canterbury.bin\"\n",
    "COMPRESSED_PATH = \"../out/compressed_vectorized.bin\"\n",
    "DECOMPRESSED_PATH = \"../out/decompressed_vectorized.bin\"\n",
    "MODEL_PATH = \"../out/model_compressor_vectorized.pth\"\n",
    "\n",
    "HIDDEN_SIZE = 128\n",
    "EPOCHS = 1 \n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 64\n",
    "CHUNK_SIZE = 10_000 # Wielkość bloku dla wektoryzacji kompresji\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec25f7642b3da4",
   "metadata": {},
   "source": [
    "## 1) Importy i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8192c64624982938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T17:46:20.837383Z",
     "start_time": "2026-01-23T17:46:20.835329Z"
    }
   },
   "outputs": [],
   "source": [
    "class ByteDataset(Dataset):\n",
    "    def __init__(self, file_path, seq_len):\n",
    "        print(f\"Loading data from {file_path}...\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        self.data = torch.from_numpy(self.data).long()\n",
    "        self.seq_len = seq_len\n",
    "        self.n_samples = len(self.data) - seq_len - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples // SEQ_LEN\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * SEQ_LEN\n",
    "        end = start + SEQ_LEN + 1\n",
    "        \n",
    "        if end > len(self.data):\n",
    "            chunk = self.data[start:]\n",
    "            return chunk[:-1], chunk[1:]\n",
    "        \n",
    "        chunk = self.data[start:end]\n",
    "        return chunk[:-1], chunk[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda359519bc01381",
   "metadata": {},
   "source": [
    "## 2) DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ef8018365e141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T17:46:20.844024Z",
     "start_time": "2026-01-23T17:46:20.842185Z"
    }
   },
   "outputs": [],
   "source": [
    "class Compressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(257, 32)\n",
    "        self.lstm = nn.LSTM(32, HIDDEN_SIZE, batch_first=True)\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, 256)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        logits = self.fc(out)\n",
    "        return logits, hidden\n",
    "    \n",
    "    def _get_probs(self, x, hidden):\n",
    "        with torch.no_grad():\n",
    "            logits, hidden = self(x, hidden)\n",
    "            probs = torch.softmax(logits[0, 0], dim=0).cpu().numpy().astype(np.float32)\n",
    "        return probs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449ab43c1a4f84",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0118a8b0ac60aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T17:46:20.848262Z",
     "start_time": "2026-01-23T17:46:20.846009Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_path, epochs=EPOCHS):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    dataset = ByteDataset(train_path, SEQ_LEN)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {i + 1}/{epochs}\", unit=\"batch\")\n",
    "\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits.view(-1, 256), y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / steps\n",
    "        bpc = avg_loss / 0.693147\n",
    "        history.append({'loss': avg_loss, 'bpc': bpc})\n",
    "        print(f\"Epoch {i + 1}/{epochs} | Loss: {avg_loss:.4f} | BPC: {bpc:.4f}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training finished in {total_time:.2f} seconds.\")\n",
    "    return history, total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3abd0a24f5074",
   "metadata": {},
   "source": [
    "## 4) Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486d42d9dbac980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T17:46:20.854375Z",
     "start_time": "2026-01-23T17:46:20.850269Z"
    }
   },
   "outputs": [],
   "source": [
    "def compress_vectorized(model, input_path, output_path):\n",
    "    model.eval()\n",
    "    encoder = constriction.stream.queue.RangeEncoder()\n",
    "    \n",
    "    with open(input_path, \"rb\") as f:\n",
    "        data_to_compress = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    \n",
    "    length = len(data_to_compress)\n",
    "    print(f\"Compressing {length} bytes using Vectorized approach...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    last_symbol = 256 # START token\n",
    "    hidden = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Przetwarzamy w chunkach\n",
    "        for i in tqdm(range(0, length, CHUNK_SIZE), desc=\"Encoding Chunks\"):\n",
    "            chunk_target = data_to_compress[i : i + CHUNK_SIZE]\n",
    "            chunk_len = len(chunk_target)\n",
    "            \n",
    "            # Przygotowanie inputu: [last_symbol, d0, d1, ..., d_M-2]\n",
    "            input_seq = np.empty(chunk_len, dtype=np.int64)\n",
    "            input_seq[0] = last_symbol\n",
    "            if chunk_len > 1:\n",
    "                input_seq[1:] = chunk_target[:-1]\n",
    "                \n",
    "            input_tensor = torch.from_numpy(input_seq).unsqueeze(0).to(DEVICE) # [1, Seq]\n",
    "            \n",
    "            # 1. Oblicz prawdopodobieństwa dla całego chunka naraz (GPU/Model)\n",
    "            logits, hidden = model(input_tensor, hidden)            \n",
    "            \n",
    "            # 2. Kodowanie (CPU loop - szybkie w C++ constriction)\n",
    "            for j in range(chunk_len):\n",
    "                symbol = chunk_target[j]\n",
    "                probs = torch.softmax(logits[0, j], dim=0).cpu().numpy().astype(np.float32)\n",
    "                dist = constriction.stream.model.Categorical(probs[j], perfect=False)\n",
    "                encoder.encode(int(symbol), dist)\n",
    "                \n",
    "            last_symbol = chunk_target[-1]\n",
    "\n",
    "    compressed_bits = encoder.get_compressed()\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(struct.pack('<I', length))\n",
    "        f.write(compressed_bits.tobytes())\n",
    "        \n",
    "    duration = time.time() - start_time\n",
    "    original_size = length\n",
    "    compressed_size = os.path.getsize(output_path)\n",
    "    ratio = original_size / compressed_size\n",
    "    bpc = (compressed_size * 8) / original_size\n",
    "    \n",
    "    print(f\"Compression finished in {duration:.2f}s\")\n",
    "    print(f\"Original size: {original_size} B\")\n",
    "    print(f\"Compressed size: {compressed_size} B\")\n",
    "    print(f\"Compression Ratio: {ratio:.2f}x\")\n",
    "    print(f\"Bits Per Character (BPC): {bpc:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'time': duration,\n",
    "        'original_size': original_size,\n",
    "        'compressed_size': compressed_size,\n",
    "        'ratio': ratio,\n",
    "        'bpc': bpc,\n",
    "        'speed_bps': original_size / duration\n",
    "    }\n",
    "\n",
    "@torch.inference_mode()\n",
    "def decompress_optimized(model, input_path, output_path):\n",
    "    model.eval()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with open(input_path, \"rb\") as f:\n",
    "        orig_len = struct.unpack('<I', f.read(4))[0]\n",
    "        bits = np.frombuffer(f.read(), dtype=np.uint32)\n",
    "\n",
    "    decoder = constriction.stream.queue.RangeDecoder(bits)\n",
    "    decoded_data = []\n",
    "    curr_symbol = torch.tensor([[256]], dtype=torch.long, device=DEVICE)\n",
    "    hidden = None\n",
    "\n",
    "    print(f\"Decompressing {orig_len} bytes...\")\n",
    "    \n",
    "    # Pętla po jednym symbolu - wąskie gardło\n",
    "    for _ in tqdm(range(orig_len), desc=\"Decoding\"):\n",
    "        probs, hidden = model._get_probs(curr_symbol, hidden)\n",
    "        dist = constriction.stream.model.Categorical(probs, perfect=False)\n",
    "        symbol = decoder.decode(dist)\n",
    "        decoded_data.append(symbol)\n",
    "        curr_symbol = torch.tensor([[symbol]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(bytes(decoded_data))\n",
    "        \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Decompression finished in {duration:.2f}s\")\n",
    "    \n",
    "    return {\n",
    "        'time': duration,\n",
    "        'speed_bps': orig_len / duration\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d0f628455caaa",
   "metadata": {},
   "source": [
    "## 6) Train i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2766037d94dfe54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T17:46:31.476338Z",
     "start_time": "2026-01-23T17:46:20.857496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING (Silesia) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/ccfc3jl55cz0ly_08hkwz2g40000gn/T/ipykernel_23808/836811189.py:7: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  self.data = torch.from_numpy(self.data).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/all_silesia.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 234/25654 [00:09<17:53, 23.68batch/s, loss=2.42]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. Trening na Silesia Corpus\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== TRAINING (Silesia) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_metrics, train_time = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m torch.save(model.state_dict(), MODEL_PATH)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. Kompresja na Canterbury Corpus (Test)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_path, epochs)\u001b[39m\n\u001b[32m     18\u001b[39m x, y = x.to(DEVICE), y.to(DEVICE)\n\u001b[32m     19\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m logits, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m loss = criterion(logits.view(-\u001b[32m1\u001b[39m, \u001b[32m256\u001b[39m), y.view(-\u001b[32m1\u001b[39m))\n\u001b[32m     22\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-compressor/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-compressor/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mCompressor.forward\u001b[39m\u001b[34m(self, x, hidden)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      9\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.embed(x)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     out, hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.fc(out)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, hidden\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-compressor/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-compressor/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/llm-compressor/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1127\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1124\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1127\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1139\u001b[39m     result = _VF.lstm(\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1141\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1149\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = Compressor().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# 1. Trening na Silesia Corpus\n",
    "# print(\"=== TRAINING (Silesia) ===\")\n",
    "# train_metrics, train_time = train_model(model, TRAIN_PATH)\n",
    "\n",
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "# 2. Kompresja na Canterbury Corpus (Test)\n",
    "print(\"\\n=== COMPRESSION (Canterbury) ===\")\n",
    "comp_metrics = compress_vectorized(model, TEST_PATH, COMPRESSED_PATH)\n",
    "\n",
    "# 3. Dekompresja\n",
    "print(\"\\n=== DECOMPRESSION (Canterbury) ===\")\n",
    "decomp_metrics = decompress_optimized(model, COMPRESSED_PATH, DECOMPRESSED_PATH)\n",
    "\n",
    "# 4. Check\n",
    "with open(TEST_PATH, 'rb') as f1, open(DECOMPRESSED_PATH, 'rb') as f2:\n",
    "    if f1.read() == f2.read():\n",
    "        print(\"\\nSUCCESS: Validated!\")\n",
    "    else:\n",
    "        print(\"\\nFAILURE: Mismatch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc339fee35633f8f",
   "metadata": {},
   "source": [
    "## 7) Podsumowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f612b98767d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Baseline Results:\")\n",
    "# print(f\"Training Time: {train_time:.2f}s\")\n",
    "print(f\"Compression Speed: {comp_metrics['speed_bps']:.2f} B/s\")\n",
    "print(f\"Decompression Speed: {decomp_metrics['speed_bps']:.2f} B/s\")\n",
    "print(f\"Compression Ratio: {comp_metrics['ratio']:.2f}x\")\n",
    "print(f\"BPC: {comp_metrics['bpc']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add39301",
   "metadata": {},
   "source": [
    "# Wnioski\n",
    "\n",
    "batch-processing powoduje wykrzaczenie się precyzji floatow w pytorchu. \n",
    "Dla entropy-codera, praowdpodbienstwa muszą być IDENTYCZNE, zeby moc odkodować poprawnie bez utraty informacji.\n",
    "\n",
    "Dalsze kroki:\n",
    "- kwantyzacja prawdopodobienstw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
